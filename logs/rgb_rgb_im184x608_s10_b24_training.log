2025-04-25 15:59:16,836 - INFO - Training trajectories: [('Kite_training/sunny', 'trajectory_0000'), ('Kite_training/sunny', 'trajectory_0001'), ('Kite_training/sunny', 'trajectory_0002'), ('Kite_training/sunny', 'trajectory_0003'), ('Kite_training/sunny', 'trajectory_0004'), ('Kite_training/sunny', 'trajectory_0005'), ('Kite_training/sunny', 'trajectory_0006'), ('Kite_training/sunny', 'trajectory_0007')], Count: 8
2025-04-25 15:59:16,836 - INFO - Validation trajectories: [('Kite_training/sunny', 'trajectory_0008'), ('Kite_training/sunny', 'trajectory_0009'), ('Kite_training/sunny', 'trajectory_0010'), ('Kite_training/sunny', 'trajectory_0011'), ('Kite_training/sunny', 'trajectory_0012'), ('Kite_training/sunny', 'trajectory_0013'), ('Kite_training/sunny', 'trajectory_0014')], Count: 7
2025-04-25 15:59:16,836 - INFO - Generating new data info (files not found)
2025-04-25 15:59:17,062 - INFO - Number of training samples: 5871
2025-04-25 15:59:17,062 - INFO - Number of validation samples: 1713
2025-04-25 15:59:17,168 - INFO - Number of training batches: 244
2025-04-25 15:59:17,168 - INFO - Number of validation batches: 71
2025-04-25 15:59:17,168 - INFO - Instantiating RGBVO model
2025-04-25 15:59:18,140 - INFO - 
==== MODEL DIAGNOSIS ====
2025-04-25 15:59:18,140 - INFO - Model type: rgb
2025-04-25 15:59:18,140 - INFO - Model class: RGBVO
2025-04-25 15:59:18,140 - INFO - Total parameters: 149,518,326
2025-04-25 15:59:18,140 - INFO - Trainable parameters: 149,518,326
2025-04-25 15:59:18,144 - DEBUG - rgb_deepvo.conv1.0.weight: shape=torch.Size([64, 6, 7, 7]), mean=0.0008, std=0.0828
2025-04-25 15:59:18,150 - DEBUG - rgb_deepvo.conv1.1.weight: shape=torch.Size([64]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv1.1.bias: shape=torch.Size([64]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv2.0.weight: shape=torch.Size([128, 64, 5, 5]), mean=-0.0000, std=0.0353
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv2.1.weight: shape=torch.Size([128]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv2.1.bias: shape=torch.Size([128]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv3.0.weight: shape=torch.Size([256, 128, 5, 5]), mean=-0.0000, std=0.0250
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv3.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,151 - DEBUG - rgb_deepvo.conv3.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv3_1.0.weight: shape=torch.Size([256, 256, 3, 3]), mean=0.0000, std=0.0295
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv3_1.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv3_1.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv4.0.weight: shape=torch.Size([512, 256, 3, 3]), mean=0.0000, std=0.0294
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv4.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv4.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv4_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 15:59:18,152 - DEBUG - rgb_deepvo.conv4_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv4_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv5.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=0.0000, std=0.0208
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv5.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv5.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv5_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv5_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,153 - DEBUG - rgb_deepvo.conv5_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,154 - DEBUG - rgb_deepvo.conv6.0.weight: shape=torch.Size([1024, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 15:59:18,154 - DEBUG - rgb_deepvo.conv6.1.weight: shape=torch.Size([1024]), mean=1.0000, std=0.0000
2025-04-25 15:59:18,154 - DEBUG - rgb_deepvo.conv6.1.bias: shape=torch.Size([1024]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,155 - DEBUG - rgb_deepvo.rnn.weight_ih_l0: shape=torch.Size([4000, 30720]), mean=0.0000, std=0.0081
2025-04-25 15:59:18,159 - DEBUG - rgb_deepvo.rnn.weight_hh_l0: shape=torch.Size([4000, 1000]), mean=0.0000, std=0.0447
2025-04-25 15:59:18,159 - DEBUG - rgb_deepvo.rnn.bias_ih_l0: shape=torch.Size([4000]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,159 - DEBUG - rgb_deepvo.rnn.bias_hh_l0: shape=torch.Size([4000]), mean=0.2500, std=0.4331
2025-04-25 15:59:18,159 - DEBUG - rgb_deepvo.rnn.weight_ih_l1: shape=torch.Size([4000, 1000]), mean=0.0000, std=0.0447
2025-04-25 15:59:18,159 - DEBUG - rgb_deepvo.rnn.weight_hh_l1: shape=torch.Size([4000, 1000]), mean=0.0000, std=0.0447
2025-04-25 15:59:18,160 - DEBUG - rgb_deepvo.rnn.bias_ih_l1: shape=torch.Size([4000]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,160 - DEBUG - rgb_deepvo.rnn.bias_hh_l1: shape=torch.Size([4000]), mean=0.2500, std=0.4331
2025-04-25 15:59:18,160 - DEBUG - rgb_deepvo.linear.weight: shape=torch.Size([6, 1000]), mean=0.0011, std=0.0454
2025-04-25 15:59:18,160 - DEBUG - rgb_deepvo.linear.bias: shape=torch.Size([6]), mean=0.0000, std=0.0000
2025-04-25 15:59:18,160 - INFO - Testing forward pass with dummy data...
2025-04-25 15:59:18,339 - INFO - Forward pass successful. Output shape: torch.Size([2, 9, 6])
2025-04-25 15:59:18,340 - INFO - Model has 64 parameters
2025-04-25 15:59:18,340 - INFO - Sample model keys: ['rgb_deepvo.conv1.0.weight', 'rgb_deepvo.conv1.1.weight', 'rgb_deepvo.conv1.1.bias', 'rgb_deepvo.conv1.1.running_mean', 'rgb_deepvo.conv1.1.running_var', 'rgb_deepvo.conv1.1.num_batches_tracked', 'rgb_deepvo.conv2.0.weight', 'rgb_deepvo.conv2.1.weight', 'rgb_deepvo.conv2.1.bias', 'rgb_deepvo.conv2.1.running_mean']
2025-04-25 15:59:18,340 - INFO - Target prefixes that exist in model: ['rgb_deepvo']
2025-04-25 15:59:18,340 - INFO - Extended target prefixes: ['rgb_deepvo', 'rgb_deepvo.conv1', 'rgb_deepvo.conv2', 'rgb_deepvo.conv3', 'rgb_deepvo.conv3_1', 'rgb_deepvo.conv4', 'rgb_deepvo.conv4_1', 'rgb_deepvo.conv5', 'rgb_deepvo.conv5_1', 'rgb_deepvo.conv6']
2025-04-25 15:59:18,340 - INFO - Loading pre-trained FlowNet weights from /home/krkavinda/DeepVO-pytorch/FlowNet_models/pytorch/flownets_bn_EPE2.459.pth
2025-04-25 15:59:18,404 - INFO - Found 'state_dict' key in weights file, using it for loading
2025-04-25 15:59:18,405 - INFO - Found 45 matches using prefixes
2025-04-25 15:59:18,405 - INFO - Successfully loaded 45 layers from FlowNet weights
2025-04-25 15:59:18,405 - INFO -   - 45 layers matched for rgb_deepvo
2025-04-25 15:59:18,406 - INFO - 
==== VALIDATING DATALOADERS ====
2025-04-25 15:59:18,406 - INFO - Checking Training dataloader...
2025-04-25 15:59:31,700 - INFO - Training batch sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 15:59:31,701 - INFO - Training RGB shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 15:59:31,720 - INFO - Training RGB stats: min=-4.2093, max=0.5773, mean=-2.0916
2025-04-25 15:59:31,749 - INFO - Training Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 15:59:31,752 - INFO - Training Ground truth stats: min=-0.8689, max=0.8018, mean=0.0569
2025-04-25 15:59:31,752 - INFO - Training Trajectory IDs: [['Kite_training/sunny', 'trajectory_0003'], ['Kite_training/sunny', 'trajectory_0002'], ['Kite_training/sunny', 'trajectory_0003']]
2025-04-25 15:59:31,941 - INFO - Training forward pass successful. Output shape: torch.Size([24, 9, 6])
2025-04-25 15:59:31,941 - INFO - Training loss calculation successful. Loss: 9.147794
2025-04-25 15:59:31,941 - INFO - Checking Validation dataloader...
2025-04-25 15:59:47,529 - INFO - Validation batch sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 15:59:47,530 - INFO - Validation RGB shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 15:59:47,549 - INFO - Validation RGB stats: min=-4.2093, max=0.5773, mean=-1.9380
2025-04-25 15:59:47,582 - INFO - Validation Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 15:59:47,582 - INFO - Validation Ground truth stats: min=-0.5746, max=0.7053, mean=0.0264
2025-04-25 15:59:47,582 - INFO - Validation Trajectory IDs: [['Kite_training/sunny', 'trajectory_0014'], ['Kite_training/sunny', 'trajectory_0013'], ['Kite_training/sunny', 'trajectory_0010']]
2025-04-25 15:59:47,764 - INFO - Validation forward pass successful. Output shape: torch.Size([24, 9, 6])
2025-04-25 15:59:47,765 - INFO - Validation loss calculation successful. Loss: 8.391264
2025-04-25 15:59:47,765 - INFO - 
==== VALIDATING LOSS CALCULATION ====
2025-04-25 15:59:57,515 - INFO - Batch 0: Model loss = 13.131069, Manual loss = 13.131071
2025-04-25 15:59:57,516 - INFO -   Difference: 0.000002
2025-04-25 16:00:02,322 - INFO - Batch 1: Model loss = 13.264915, Manual loss = 13.264915
2025-04-25 16:00:02,323 - INFO -   Difference: 0.000000
2025-04-25 16:00:02,541 - INFO - Batch 2: Model loss = 15.472156, Manual loss = 15.472156
2025-04-25 16:00:02,541 - INFO -   Difference: 0.000000
2025-04-25 16:00:02,779 - INFO - Batch 3: Model loss = 16.624584, Manual loss = 16.624588
2025-04-25 16:00:02,779 - INFO -   Difference: 0.000004
2025-04-25 16:00:03,035 - INFO - Batch 4: Model loss = 13.786757, Manual loss = 13.786755
2025-04-25 16:00:03,036 - INFO -   Difference: 0.000003
2025-04-25 16:00:05,454 - INFO - Validated 5 batches.
2025-04-25 16:00:05,455 - INFO - Average validation loss: 14.455896
2025-04-25 16:00:05,455 - INFO - Min: 13.131069, Max: 16.624584
2025-04-25 16:00:05,455 - INFO - Starting training for 100 epochs
2025-04-25 16:00:13,971 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:00:13,974 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:00:13,975 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:00:13,978 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:00:14,046 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-1.4967e-04, -8.6067e-05,  6.5170e-05, -5.1677e-01, -5.8725e-01,
          5.6747e-02],
        [-2.0428e-04, -5.8155e-05,  7.6758e-05, -5.1709e-01, -5.8769e-01,
          5.6527e-02],
        [-2.3851e-04, -2.7921e-05,  8.4506e-05, -5.1741e-01, -5.8812e-01,
          5.6277e-02]], device='cuda:0')
2025-04-25 16:01:47,418 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:01:47,421 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:01:47,421 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:01:47,424 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:01:47,429 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0007, -0.0006, -0.0007, -0.4686,  0.3169, -0.0664],
        [ 0.0006, -0.0006, -0.0008, -0.4691,  0.3173, -0.0666],
        [ 0.0005, -0.0006, -0.0009, -0.4695,  0.3176, -0.0667]],
       device='cuda:0')
2025-04-25 16:02:01,751 - INFO - Epoch 1/100, Train Loss: 1.523303, Valid Loss: 0.084958, ETA: 3:11:53
2025-04-25 16:02:04,544 - INFO - New best validation loss: 0.084958
2025-04-25 16:02:07,311 - INFO - New best training loss: 1.523303
2025-04-25 16:02:22,049 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:02:22,050 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:02:22,051 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:02:22,053 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:02:22,056 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0016, -0.0007,  0.0034,  0.1866,  0.2571, -0.0056],
        [ 0.0017, -0.0008,  0.0031,  0.1836,  0.2588, -0.0051],
        [ 0.0017, -0.0008,  0.0028,  0.1806,  0.2607, -0.0049]],
       device='cuda:0')
2025-04-25 16:03:53,726 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:03:53,729 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:03:53,729 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:03:53,733 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:03:53,738 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 6.6227e-04, -5.8314e-05,  5.0775e-03,  3.1597e-02, -4.4257e-01,
         -4.4325e-02],
        [ 7.0471e-04,  5.1901e-05,  5.0106e-03,  2.9836e-02, -4.4281e-01,
         -4.3947e-02],
        [ 7.2331e-04,  1.4248e-04,  4.9520e-03,  2.8116e-02, -4.4303e-01,
         -4.3603e-02]], device='cuda:0')
2025-04-25 16:04:05,335 - INFO - Epoch 2/100, Train Loss: 0.054673, Valid Loss: 0.147008, ETA: 3:11:21
2025-04-25 16:04:08,565 - INFO - New best training loss: 0.054673
2025-04-25 16:04:16,408 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:04:16,412 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:04:16,414 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:04:16,417 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:04:16,424 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0011,  0.0020, -0.0030,  0.1629, -0.7257, -0.0784],
        [ 0.0010,  0.0019, -0.0027,  0.1616, -0.7258, -0.0776],
        [ 0.0009,  0.0017, -0.0024,  0.1600, -0.7259, -0.0768]],
       device='cuda:0')
2025-04-25 16:05:56,262 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:05:56,265 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:05:56,266 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:05:56,269 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:05:56,275 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 1.8082e-04, -1.3241e-04,  1.2257e-05,  1.8647e-01,  2.8204e-01,
         -7.1565e-02],
        [ 3.5327e-04, -2.6112e-04,  1.6283e-05,  1.8633e-01,  2.8187e-01,
         -6.9000e-02],
        [ 5.7841e-04, -4.2927e-04,  2.1992e-05,  1.8618e-01,  2.8169e-01,
         -6.6329e-02]], device='cuda:0')
2025-04-25 16:06:06,425 - INFO - Epoch 3/100, Train Loss: 0.033085, Valid Loss: 0.124785, ETA: 3:09:47
2025-04-25 16:06:09,727 - INFO - New best training loss: 0.033085
2025-04-25 16:06:18,159 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:06:18,161 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:06:18,162 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:06:18,165 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:06:18,171 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0147, -0.0080, -0.0034,  0.4493,  0.3578, -0.1209],
        [-0.0126, -0.0065, -0.0031,  0.4490,  0.3596, -0.1192],
        [-0.0106, -0.0052, -0.0027,  0.4491,  0.3609, -0.1176]],
       device='cuda:0')
2025-04-25 16:07:55,799 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:07:55,802 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:07:55,802 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:07:55,806 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:07:55,813 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0029,  0.0045, -0.0136,  0.4811,  0.0945, -0.1439],
        [-0.0028,  0.0043, -0.0126,  0.4787,  0.0975, -0.1405],
        [-0.0027,  0.0041, -0.0116,  0.4764,  0.1000, -0.1370]],
       device='cuda:0')
2025-04-25 16:08:07,826 - INFO - Epoch 4/100, Train Loss: 0.022719, Valid Loss: 0.130751, ETA: 3:08:06
2025-04-25 16:08:11,164 - INFO - New best training loss: 0.022719
2025-04-25 16:08:23,809 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:08:23,812 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:08:23,813 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:08:23,816 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:08:23,821 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-2.2484e-04, -3.9718e-04, -4.6402e-05,  5.1552e-01, -2.7540e-01,
         -1.7389e-02],
        [-2.4461e-04, -4.2719e-04, -5.4048e-05,  5.1804e-01, -2.7675e-01,
         -2.0169e-02],
        [-2.6743e-04, -4.6216e-04, -6.2698e-05,  5.2050e-01, -2.7806e-01,
         -2.2772e-02]], device='cuda:0')
2025-04-25 16:09:51,949 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:09:51,956 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:09:51,960 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:09:51,968 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:09:51,983 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-1.7002e-03, -6.7471e-03,  9.3558e-05,  1.6256e-03, -4.9828e-01,
         -7.9135e-02],
        [-1.6207e-03, -6.4721e-03,  8.1482e-05,  6.2115e-04, -4.9923e-01,
         -7.9464e-02],
        [-1.5144e-03, -6.0811e-03,  6.8904e-05, -2.5305e-04, -5.0021e-01,
         -7.9714e-02]], device='cuda:0')
2025-04-25 16:10:10,165 - INFO - Epoch 5/100, Train Loss: 0.017444, Valid Loss: 0.126646, ETA: 3:06:36
2025-04-25 16:10:13,451 - INFO - New best training loss: 0.017444
2025-04-25 16:10:16,216 - INFO - Saved checkpoint at epoch 5
2025-04-25 16:10:28,601 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:10:28,603 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:10:28,603 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:10:28,606 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:10:28,610 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-3.8332e-04, -4.0764e-04, -7.3399e-06,  7.3870e-01, -8.9809e-02,
         -8.0464e-02],
        [-4.3861e-04, -3.7146e-04, -6.9393e-06,  7.3836e-01, -9.1893e-02,
         -8.0215e-02],
        [-4.8430e-04, -3.2787e-04, -3.5539e-06,  7.3802e-01, -9.3968e-02,
         -7.9951e-02]], device='cuda:0')
2025-04-25 16:11:56,592 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:11:56,595 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:11:56,595 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:11:56,598 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:11:56,602 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-7.3281e-05, -1.7174e-03, -1.2268e-04,  4.2378e-01,  2.0773e-01,
         -1.1593e-01],
        [-8.1884e-05, -1.6184e-03, -8.1460e-05,  4.2388e-01,  2.0747e-01,
         -1.1638e-01],
        [-7.5256e-05, -1.4846e-03, -2.6373e-05,  4.2403e-01,  2.0720e-01,
         -1.1678e-01]], device='cuda:0')
2025-04-25 16:12:09,892 - INFO - Epoch 6/100, Train Loss: 0.014030, Valid Loss: 0.131859, ETA: 3:03:35
2025-04-25 16:12:13,153 - INFO - New best training loss: 0.014030
2025-04-25 16:12:24,702 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:12:24,704 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:12:24,705 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:12:24,708 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:12:24,711 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0030, -0.0035,  0.0034,  0.7316, -0.1426, -0.0596],
        [ 0.0033, -0.0036,  0.0040,  0.7310, -0.1465, -0.0602],
        [ 0.0036, -0.0037,  0.0047,  0.7302, -0.1508, -0.0608]],
       device='cuda:0')
2025-04-25 16:13:54,180 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:13:54,183 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:13:54,183 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:13:54,186 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:13:54,190 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0025,  0.0053,  0.0044,  0.2331, -0.2081,  0.0272],
        [-0.0029,  0.0052,  0.0040,  0.2345, -0.2059,  0.0252],
        [-0.0031,  0.0050,  0.0036,  0.2360, -0.2037,  0.0227]],
       device='cuda:0')
2025-04-25 16:14:06,565 - INFO - Epoch 7/100, Train Loss: 0.012542, Valid Loss: 0.126522, ETA: 3:00:12
2025-04-25 16:14:09,763 - INFO - New best training loss: 0.012542
2025-04-25 16:14:22,962 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:14:22,965 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:14:22,966 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:14:22,969 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:14:22,973 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0019, -0.0002,  0.0075, -0.1330,  0.1642,  0.0360],
        [-0.0018, -0.0004,  0.0074, -0.1327,  0.1626,  0.0377],
        [-0.0018, -0.0005,  0.0074, -0.1324,  0.1609,  0.0394]],
       device='cuda:0')
2025-04-25 16:15:50,149 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:15:50,152 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:15:50,152 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:15:50,155 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:15:50,159 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 2.5602e-03,  8.7777e-03, -1.7670e-04,  2.6317e-01,  3.8980e-01,
         -2.1882e-01],
        [ 2.4332e-03,  8.3094e-03, -2.2214e-04,  2.6303e-01,  3.8839e-01,
         -2.1745e-01],
        [ 2.2631e-03,  7.6868e-03, -2.5770e-04,  2.6263e-01,  3.8707e-01,
         -2.1618e-01]], device='cuda:0')
2025-04-25 16:16:04,200 - INFO - Epoch 8/100, Train Loss: 0.011280, Valid Loss: 0.127417, ETA: 2:57:12
2025-04-25 16:16:07,182 - INFO - New best training loss: 0.011280
2025-04-25 16:16:17,771 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:16:17,774 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:16:17,774 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:16:17,778 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:16:17,783 - INFO - Ground truth sample (first item, first 3 frames): tensor([[0.0020, 0.0044, 0.0103, 0.3600, 0.2158, 0.1054],
        [0.0016, 0.0043, 0.0105, 0.3607, 0.2144, 0.1064],
        [0.0013, 0.0041, 0.0106, 0.3615, 0.2130, 0.1072]], device='cuda:0')
2025-04-25 16:17:45,275 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:17:45,281 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:17:45,284 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:17:45,289 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:17:45,296 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0019,  0.0044, -0.0063,  0.2457, -0.4973, -0.0983],
        [ 0.0020,  0.0043, -0.0064,  0.2466, -0.4959, -0.0974],
        [ 0.0021,  0.0043, -0.0064,  0.2475, -0.4944, -0.0964]],
       device='cuda:0')
2025-04-25 16:18:00,425 - INFO - Epoch 9/100, Train Loss: 0.010473, Valid Loss: 0.118487, ETA: 2:53:48
2025-04-25 16:18:03,525 - INFO - New best training loss: 0.010473
2025-04-25 16:18:16,683 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:18:16,686 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:18:16,686 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:18:16,689 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:18:16,693 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0013,  0.0006,  0.0069, -0.1139,  0.3984, -0.0159],
        [-0.0014,  0.0007,  0.0072, -0.1151,  0.3982, -0.0156],
        [-0.0016,  0.0008,  0.0076, -0.1161,  0.3980, -0.0153]],
       device='cuda:0')
2025-04-25 16:19:45,140 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:19:45,143 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:19:45,144 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:19:45,147 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:19:45,149 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 2.5328e-03,  4.4627e-04,  1.4295e-03,  5.5561e-01, -4.3084e-01,
          1.1858e-02],
        [ 2.7200e-03,  3.6737e-04,  1.5047e-03,  5.5737e-01, -4.2933e-01,
          1.1659e-02],
        [ 2.9309e-03,  2.9287e-04,  1.6373e-03,  5.5908e-01, -4.2783e-01,
          1.1500e-02]], device='cuda:0')
2025-04-25 16:20:12,085 - INFO - Training trajectories: [('Kite_training/sunny', 'trajectory_0000'), ('Kite_training/sunny', 'trajectory_0001'), ('Kite_training/sunny', 'trajectory_0002'), ('Kite_training/sunny', 'trajectory_0003'), ('Kite_training/sunny', 'trajectory_0004'), ('Kite_training/sunny', 'trajectory_0005'), ('Kite_training/sunny', 'trajectory_0006'), ('Kite_training/sunny', 'trajectory_0007')], Count: 8
2025-04-25 16:20:12,085 - INFO - Validation trajectories: [('Kite_training/sunny', 'trajectory_0008'), ('Kite_training/sunny', 'trajectory_0009'), ('Kite_training/sunny', 'trajectory_0010'), ('Kite_training/sunny', 'trajectory_0011'), ('Kite_training/sunny', 'trajectory_0012'), ('Kite_training/sunny', 'trajectory_0013'), ('Kite_training/sunny', 'trajectory_0014')], Count: 7
2025-04-25 16:20:12,171 - INFO - Using existing data info files with 15 trajectories
2025-04-25 16:20:12,171 - INFO - Number of training samples: 5871
2025-04-25 16:20:12,171 - INFO - Number of validation samples: 1713
2025-04-25 16:20:12,280 - INFO - Number of training batches: 244
2025-04-25 16:20:12,280 - INFO - Number of validation batches: 71
2025-04-25 16:20:12,280 - INFO - Instantiating RGBVO model
2025-04-25 16:20:12,853 - INFO - 
==== MODEL DIAGNOSIS ====
2025-04-25 16:20:12,853 - INFO - Model type: rgb
2025-04-25 16:20:12,853 - INFO - Model class: RGBVO
2025-04-25 16:20:12,854 - INFO - Total parameters: 80,687,878
2025-04-25 16:20:12,854 - INFO - Trainable parameters: 80,687,878
2025-04-25 16:20:12,858 - DEBUG - rgb_deepvo.conv1.0.weight: shape=torch.Size([64, 6, 7, 7]), mean=0.0004, std=0.0825
2025-04-25 16:20:12,864 - DEBUG - rgb_deepvo.conv1.1.weight: shape=torch.Size([64]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,864 - DEBUG - rgb_deepvo.conv1.1.bias: shape=torch.Size([64]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,865 - DEBUG - rgb_deepvo.conv2.0.weight: shape=torch.Size([128, 64, 5, 5]), mean=-0.0000, std=0.0354
2025-04-25 16:20:12,865 - DEBUG - rgb_deepvo.conv2.1.weight: shape=torch.Size([128]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,865 - DEBUG - rgb_deepvo.conv2.1.bias: shape=torch.Size([128]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,865 - DEBUG - rgb_deepvo.conv3.0.weight: shape=torch.Size([256, 128, 5, 5]), mean=-0.0000, std=0.0250
2025-04-25 16:20:12,865 - DEBUG - rgb_deepvo.conv3.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,865 - DEBUG - rgb_deepvo.conv3.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv3_1.0.weight: shape=torch.Size([256, 256, 3, 3]), mean=0.0000, std=0.0294
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv3_1.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv3_1.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv4.0.weight: shape=torch.Size([512, 256, 3, 3]), mean=0.0000, std=0.0294
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv4.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv4.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv4_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=0.0000, std=0.0208
2025-04-25 16:20:12,866 - DEBUG - rgb_deepvo.conv4_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv4_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv5.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv5.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv5.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv5_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv5_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv5_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,867 - DEBUG - rgb_deepvo.conv6.0.weight: shape=torch.Size([1024, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 16:20:12,868 - DEBUG - rgb_deepvo.conv6.1.weight: shape=torch.Size([1024]), mean=1.0000, std=0.0000
2025-04-25 16:20:12,868 - DEBUG - rgb_deepvo.conv6.1.bias: shape=torch.Size([1024]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,869 - DEBUG - rgb_deepvo.rnn.weight_ih_l0: shape=torch.Size([2048, 30720]), mean=-0.0000, std=0.0081
2025-04-25 16:20:12,870 - DEBUG - rgb_deepvo.rnn.weight_hh_l0: shape=torch.Size([2048, 512]), mean=-0.0001, std=0.0625
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.rnn.bias_ih_l0: shape=torch.Size([2048]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.rnn.bias_hh_l0: shape=torch.Size([2048]), mean=0.2500, std=0.4331
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.rnn.weight_ih_l1: shape=torch.Size([2048, 512]), mean=0.0001, std=0.0625
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.rnn.weight_hh_l1: shape=torch.Size([2048, 512]), mean=0.0001, std=0.0625
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.rnn.bias_ih_l1: shape=torch.Size([2048]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.rnn.bias_hh_l1: shape=torch.Size([2048]), mean=0.2500, std=0.4331
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.linear.weight: shape=torch.Size([6, 512]), mean=0.0001, std=0.0613
2025-04-25 16:20:12,871 - DEBUG - rgb_deepvo.linear.bias: shape=torch.Size([6]), mean=0.0000, std=0.0000
2025-04-25 16:20:12,872 - INFO - Testing forward pass with dummy data...
2025-04-25 16:20:12,969 - INFO - Forward pass successful. Output shape: torch.Size([2, 9, 6])
2025-04-25 16:20:12,970 - INFO - Model has 64 parameters
2025-04-25 16:20:12,970 - INFO - Sample model keys: ['rgb_deepvo.conv1.0.weight', 'rgb_deepvo.conv1.1.weight', 'rgb_deepvo.conv1.1.bias', 'rgb_deepvo.conv1.1.running_mean', 'rgb_deepvo.conv1.1.running_var', 'rgb_deepvo.conv1.1.num_batches_tracked', 'rgb_deepvo.conv2.0.weight', 'rgb_deepvo.conv2.1.weight', 'rgb_deepvo.conv2.1.bias', 'rgb_deepvo.conv2.1.running_mean']
2025-04-25 16:20:12,970 - INFO - Target prefixes that exist in model: ['rgb_deepvo']
2025-04-25 16:20:12,970 - INFO - Extended target prefixes: ['rgb_deepvo', 'rgb_deepvo.conv1', 'rgb_deepvo.conv2', 'rgb_deepvo.conv3', 'rgb_deepvo.conv3_1', 'rgb_deepvo.conv4', 'rgb_deepvo.conv4_1', 'rgb_deepvo.conv5', 'rgb_deepvo.conv5_1', 'rgb_deepvo.conv6']
2025-04-25 16:20:12,970 - INFO - Loading pre-trained FlowNet weights from /home/krkavinda/DeepVO-pytorch/FlowNet_models/pytorch/flownets_bn_EPE2.459.pth
2025-04-25 16:20:13,033 - INFO - Found 'state_dict' key in weights file, using it for loading
2025-04-25 16:20:13,034 - INFO - Found 45 matches using prefixes
2025-04-25 16:20:13,035 - INFO - Successfully loaded 45 layers from FlowNet weights
2025-04-25 16:20:13,035 - INFO -   - 45 layers matched for rgb_deepvo
2025-04-25 16:20:13,035 - INFO - 
==== VALIDATING DATALOADERS ====
2025-04-25 16:20:13,035 - INFO - Checking Training dataloader...
2025-04-25 16:20:26,258 - INFO - Training batch sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:20:26,258 - INFO - Training RGB shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:20:26,278 - INFO - Training RGB stats: min=-4.2093, max=0.5773, mean=-2.0005
2025-04-25 16:20:26,315 - INFO - Training Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:20:26,318 - INFO - Training Ground truth stats: min=-0.7066, max=0.7453, mean=0.0366
2025-04-25 16:20:26,318 - INFO - Training Trajectory IDs: [['Kite_training/sunny', 'trajectory_0005'], ['Kite_training/sunny', 'trajectory_0002'], ['Kite_training/sunny', 'trajectory_0003']]
2025-04-25 16:20:26,505 - INFO - Training forward pass successful. Output shape: torch.Size([24, 9, 6])
2025-04-25 16:20:26,505 - INFO - Training loss calculation successful. Loss: 0.500192
2025-04-25 16:20:26,505 - INFO - Checking Validation dataloader...
2025-04-25 16:20:42,521 - INFO - Validation batch sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:20:42,521 - INFO - Validation RGB shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:20:42,542 - INFO - Validation RGB stats: min=-4.2093, max=0.5773, mean=-2.0017
2025-04-25 16:20:42,572 - INFO - Validation Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:20:42,572 - INFO - Validation Ground truth stats: min=-0.6319, max=0.5982, mean=0.0013
2025-04-25 16:20:42,572 - INFO - Validation Trajectory IDs: [['Kite_training/sunny', 'trajectory_0008'], ['Kite_training/sunny', 'trajectory_0009'], ['Kite_training/sunny', 'trajectory_0010']]
2025-04-25 16:20:42,752 - INFO - Validation forward pass successful. Output shape: torch.Size([24, 9, 6])
2025-04-25 16:20:42,752 - INFO - Validation loss calculation successful. Loss: 0.496561
2025-04-25 16:20:42,752 - INFO - 
==== VALIDATING LOSS CALCULATION ====
2025-04-25 16:20:52,546 - INFO - Batch 0: Model loss = 0.304985, Manual loss = 0.304985
2025-04-25 16:20:52,548 - INFO -   Difference: 0.000000
2025-04-25 16:20:54,785 - INFO - Batch 1: Model loss = 0.305194, Manual loss = 0.305194
2025-04-25 16:20:54,786 - INFO -   Difference: 0.000000
2025-04-25 16:20:55,395 - INFO - Batch 2: Model loss = 0.271470, Manual loss = 0.271470
2025-04-25 16:20:55,396 - INFO -   Difference: 0.000000
2025-04-25 16:20:55,593 - INFO - Batch 3: Model loss = 0.295327, Manual loss = 0.295327
2025-04-25 16:20:55,594 - INFO -   Difference: 0.000000
2025-04-25 16:20:55,793 - INFO - Batch 4: Model loss = 0.294545, Manual loss = 0.294545
2025-04-25 16:20:55,794 - INFO -   Difference: 0.000000
2025-04-25 16:20:56,684 - INFO - Validated 5 batches.
2025-04-25 16:20:56,684 - INFO - Average validation loss: 0.294304
2025-04-25 16:20:56,684 - INFO - Min: 0.271470, Max: 0.305194
2025-04-25 16:20:56,684 - INFO - Starting training for 100 epochs
2025-04-25 16:21:05,098 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:21:05,101 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:21:05,101 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:21:05,104 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:21:05,165 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 2.2959e-04, -2.2272e-04,  1.4841e-05,  7.8394e-01,  3.5144e-01,
          3.3656e-02],
        [ 3.0736e-04, -1.4074e-04,  4.2713e-05,  7.8441e-01,  3.4908e-01,
          3.2801e-02],
        [ 3.6757e-04, -6.9426e-05,  6.5162e-05,  7.8488e-01,  3.4672e-01,
          3.2004e-02]], device='cuda:0')
2025-04-25 16:22:36,593 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:22:36,596 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:22:36,596 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:22:36,599 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:22:36,603 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 3.7962e-04,  1.6730e-03,  3.9179e-05, -4.0033e-01,  1.7544e-01,
          2.1181e-01],
        [ 4.9824e-04,  1.4963e-03,  3.5915e-05, -3.9966e-01,  1.7654e-01,
          2.1161e-01],
        [ 6.0620e-04,  1.2998e-03,  3.3767e-05, -3.9896e-01,  1.7768e-01,
          2.1147e-01]], device='cuda:0')
2025-04-25 16:22:48,711 - INFO - Epoch 1/100, Train Loss: 0.125839, Valid Loss: 0.101519, ETA: 3:04:50
2025-04-25 16:22:49,703 - INFO - New best validation loss: 0.101519
2025-04-25 16:22:50,739 - INFO - New best training loss: 0.125839
2025-04-25 16:22:58,446 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:22:58,448 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:22:58,449 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:22:58,452 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:22:58,457 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-1.3017e-03, -3.3843e-04,  9.8527e-04,  3.2649e-01,  2.3325e-02,
          3.6617e-03],
        [-9.7528e-04, -3.4279e-04,  1.1285e-03,  3.2529e-01,  2.6182e-02,
          1.6681e-03],
        [-7.7282e-04, -3.1458e-04,  1.2497e-03,  3.2409e-01,  2.8922e-02,
         -3.4406e-04]], device='cuda:0')
2025-04-25 16:24:30,403 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:24:30,405 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:24:30,406 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:24:30,409 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:24:30,414 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 9.9866e-04,  2.6384e-03,  6.9676e-05,  1.5808e-01, -1.1305e-01,
         -3.2505e-02],
        [ 1.1411e-03,  2.6535e-03,  7.7073e-05,  1.5883e-01, -1.1417e-01,
         -3.1426e-02],
        [ 1.2833e-03,  2.6044e-03,  8.1588e-05,  1.5956e-01, -1.1529e-01,
         -3.0562e-02]], device='cuda:0')
2025-04-25 16:24:41,352 - INFO - Epoch 2/100, Train Loss: 0.055500, Valid Loss: 0.244170, ETA: 3:01:49
2025-04-25 16:24:42,295 - INFO - New best training loss: 0.055500
2025-04-25 16:24:55,556 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:24:55,559 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:24:55,559 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:24:55,562 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:24:55,566 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0005, -0.0003, -0.0013,  0.2687,  0.1404, -0.0215],
        [-0.0005, -0.0003, -0.0011,  0.2692,  0.1402, -0.0221],
        [-0.0005, -0.0004, -0.0009,  0.2696,  0.1399, -0.0227]],
       device='cuda:0')
2025-04-25 16:26:20,194 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:26:20,197 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:26:20,197 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:26:20,200 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:26:20,205 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0098, -0.0068,  0.0106,  0.1137,  0.2266, -0.2387],
        [ 0.0096, -0.0061,  0.0099,  0.1141,  0.2219, -0.2416],
        [ 0.0092, -0.0054,  0.0092,  0.1146,  0.2175, -0.2433]],
       device='cuda:0')
2025-04-25 16:26:34,497 - INFO - Epoch 3/100, Train Loss: 0.039375, Valid Loss: 0.241720, ETA: 3:00:26
2025-04-25 16:26:35,451 - INFO - New best training loss: 0.039375
2025-04-25 16:26:44,193 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:26:44,196 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:26:44,196 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:26:44,199 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:26:44,204 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-2.4097e-05,  1.9848e-05,  1.5151e-03,  6.3862e-02,  8.0225e-01,
          1.0533e-02],
        [ 8.5186e-05,  1.2513e-04,  1.6438e-03,  6.4195e-02,  8.0216e-01,
          1.0314e-02],
        [ 2.0285e-04,  2.4180e-04,  1.7817e-03,  6.4638e-02,  8.0205e-01,
          1.0010e-02]], device='cuda:0')
2025-04-25 16:28:13,338 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:28:13,341 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:28:13,341 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:28:13,344 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:28:13,349 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-4.6101e-04, -2.0140e-04, -5.4554e-05,  4.2117e-01,  2.6249e-01,
         -7.6836e-02],
        [-4.8890e-04, -1.7366e-04, -5.8273e-05,  4.2216e-01,  2.6269e-01,
         -7.6199e-02],
        [-4.9680e-04, -1.4629e-04, -5.8564e-05,  4.2316e-01,  2.6289e-01,
         -7.5553e-02]], device='cuda:0')
2025-04-25 16:28:27,755 - INFO - Epoch 4/100, Train Loss: 0.030870, Valid Loss: 0.202373, ETA: 2:58:51
2025-04-25 16:28:28,718 - INFO - New best training loss: 0.030870
2025-04-25 16:28:39,172 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:28:39,174 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:28:39,175 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:28:39,178 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:28:39,181 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 3.0688e-05,  1.2703e-02, -6.9018e-03,  4.0232e-01, -2.2952e-01,
          5.6558e-02],
        [ 8.1116e-04,  1.1376e-02, -8.1748e-03,  3.9836e-01, -2.2934e-01,
          5.9002e-02],
        [ 1.6811e-03,  9.8357e-03, -9.6339e-03,  3.9443e-01, -2.2875e-01,
          6.0926e-02]], device='cuda:0')
2025-04-25 16:30:04,817 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:30:04,820 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:30:04,821 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:30:04,823 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:30:04,827 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 8.8877e-05, -9.2832e-04, -2.4252e-03, -4.7026e-01,  3.2971e-01,
         -7.0117e-02],
        [ 8.8950e-05, -9.6532e-04, -2.5119e-03, -4.7113e-01,  3.2919e-01,
         -6.9926e-02],
        [ 8.7623e-05, -1.0077e-03, -2.6337e-03, -4.7200e-01,  3.2863e-01,
         -6.9725e-02]], device='cuda:0')
2025-04-25 16:30:16,604 - INFO - Epoch 5/100, Train Loss: 0.026264, Valid Loss: 0.181296, ETA: 2:55:45
2025-04-25 16:30:17,546 - INFO - New best training loss: 0.026264
2025-04-25 16:30:18,598 - INFO - Saved checkpoint at epoch 5
2025-04-25 16:30:27,702 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:30:27,704 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:30:27,705 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:30:27,708 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:30:27,712 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0027, -0.0022,  0.0006, -0.1952,  0.2707,  0.0619],
        [ 0.0027, -0.0019,  0.0006, -0.1998,  0.2705,  0.0635],
        [ 0.0027, -0.0017,  0.0006, -0.2044,  0.2703,  0.0651]],
       device='cuda:0')
2025-04-25 16:31:57,602 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:31:57,604 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:31:57,604 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:31:57,607 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:31:57,611 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 1.5764e-04,  5.3455e-04,  6.9084e-04, -3.6164e-01,  2.1893e-01,
          2.2454e-01],
        [ 1.5934e-04,  4.8361e-04,  8.6457e-04, -3.6050e-01,  2.2049e-01,
          2.2450e-01],
        [ 1.6020e-04,  4.2152e-04,  1.0124e-03, -3.5930e-01,  2.2213e-01,
          2.2448e-01]], device='cuda:0')
2025-04-25 16:32:09,819 - INFO - Epoch 6/100, Train Loss: 0.022097, Valid Loss: 0.160154, ETA: 2:53:26
2025-04-25 16:32:10,772 - INFO - New best training loss: 0.022097
2025-04-25 16:32:17,109 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:32:17,114 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:32:17,115 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:32:17,118 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:32:17,124 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-5.9337e-04,  2.9182e-04, -1.7413e-03,  6.2922e-01, -6.4131e-02,
          3.8872e-02],
        [-5.1570e-04,  6.6768e-05, -1.5716e-03,  6.2909e-01, -6.4133e-02,
          3.9753e-02],
        [-4.3095e-04, -1.8660e-04, -1.3926e-03,  6.2893e-01, -6.4237e-02,
          4.0553e-02]], device='cuda:0')
2025-04-25 16:33:45,754 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:33:45,757 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:33:45,757 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:33:45,760 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:33:45,765 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-1.5587e-03, -1.2341e-04,  5.7179e-03, -3.2994e-01,  3.4105e-01,
          1.3324e-01],
        [-1.6162e-03, -3.7122e-06,  5.1973e-03, -3.2831e-01,  3.4270e-01,
          1.3357e-01],
        [-1.6753e-03,  1.4540e-04,  4.6240e-03, -3.2687e-01,  3.4417e-01,
          1.3379e-01]], device='cuda:0')
2025-04-25 16:33:59,655 - INFO - Epoch 7/100, Train Loss: 0.020585, Valid Loss: 0.148360, ETA: 2:51:03
2025-04-25 16:34:00,604 - INFO - New best training loss: 0.020585
2025-04-25 16:34:11,143 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:34:11,146 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:34:11,146 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:34:11,149 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:34:11,154 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0028,  0.0013, -0.0056,  0.3439,  0.1700,  0.0062],
        [-0.0027,  0.0010, -0.0053,  0.3426,  0.1717,  0.0080],
        [-0.0027,  0.0008, -0.0051,  0.3413,  0.1732,  0.0098]],
       device='cuda:0')
2025-04-25 16:35:41,941 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:35:41,943 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:35:41,944 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:35:41,947 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:35:41,950 - INFO - Ground truth sample (first item, first 3 frames): tensor([[0.0075, 0.0064, 0.0111, 0.4166, 0.3593, 0.0686],
        [0.0072, 0.0071, 0.0130, 0.4163, 0.3586, 0.0685],
        [0.0067, 0.0079, 0.0149, 0.4164, 0.3574, 0.0687]], device='cuda:0')
2025-04-25 16:35:53,475 - INFO - Epoch 8/100, Train Loss: 0.019184, Valid Loss: 0.151447, ETA: 2:49:25
2025-04-25 16:35:54,433 - INFO - New best training loss: 0.019184
2025-04-25 16:36:04,730 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:36:04,733 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:36:04,733 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:36:04,736 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:36:04,740 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0026, -0.0011, -0.0236, -0.0726,  0.7660, -0.0603],
        [-0.0024, -0.0012, -0.0259, -0.0896,  0.7621, -0.0600],
        [-0.0023, -0.0013, -0.0281, -0.1082,  0.7575, -0.0598]],
       device='cuda:0')
2025-04-25 16:37:31,684 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:37:31,686 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:37:31,687 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:37:31,689 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:37:31,694 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0007, -0.0008, -0.0043,  0.3722,  0.1716, -0.0388],
        [-0.0009, -0.0008, -0.0046,  0.3727,  0.1730, -0.0386],
        [-0.0010, -0.0007, -0.0048,  0.3731,  0.1745, -0.0383]],
       device='cuda:0')
2025-04-25 16:37:44,278 - INFO - Epoch 9/100, Train Loss: 0.017951, Valid Loss: 0.164459, ETA: 2:46:50
2025-04-25 16:37:45,238 - INFO - New best training loss: 0.017951
2025-04-25 16:37:55,668 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:37:55,672 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:37:55,672 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:37:55,675 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:37:55,681 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-5.0891e-04, -1.2016e-04, -1.3453e-04,  7.9086e-01,  3.1177e-01,
          2.8003e-02],
        [-5.2026e-04, -1.1804e-04, -1.3411e-04,  7.9079e-01,  3.0975e-01,
          2.8695e-02],
        [-5.1029e-04, -1.0719e-04, -1.2725e-04,  7.9064e-01,  3.0773e-01,
          2.9559e-02]], device='cuda:0')
2025-04-25 16:39:20,311 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:39:20,315 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:39:20,316 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:39:20,319 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:39:20,324 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-7.9730e-04,  2.4942e-03,  1.3511e-04, -6.0071e-01,  3.1442e-01,
          3.0849e-02],
        [-6.9613e-04,  2.3559e-03,  1.2452e-04, -6.0079e-01,  3.1542e-01,
          2.9978e-02],
        [-5.6695e-04,  2.1677e-03,  1.0789e-04, -6.0090e-01,  3.1639e-01,
          2.9166e-02]], device='cuda:0')
2025-04-25 16:40:04,708 - INFO - ATE: 3.0288 ± 2.5407 m
2025-04-25 16:40:04,709 - INFO - RPE Translation: 1.2644 ± 1.8903 m
2025-04-25 16:40:04,709 - INFO - RPE Rotation: 0.0120 ± 0.0186 rad
2025-04-25 16:40:04,709 - INFO - Epoch 10/100, Train Loss: 0.016573, Valid Loss: 0.139736, ETA: 2:54:28
2025-04-25 16:40:05,664 - INFO - New best training loss: 0.016573
2025-04-25 16:40:06,456 - INFO - Saved checkpoint at epoch 10
2025-04-25 16:40:17,478 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:40:17,481 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:40:17,481 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:40:17,484 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:40:17,489 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0055,  0.0030,  0.0071,  0.3423, -0.1567, -0.0030],
        [ 0.0051,  0.0032,  0.0070,  0.3421, -0.1562, -0.0004],
        [ 0.0046,  0.0034,  0.0068,  0.3419, -0.1557,  0.0023]],
       device='cuda:0')
2025-04-25 16:41:46,162 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:41:46,166 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:41:46,166 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:41:46,169 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:41:46,175 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-3.2549e-03, -4.8310e-04, -1.4398e-02,  4.3980e-01,  1.8443e-01,
         -1.0901e-01],
        [-3.2611e-03, -2.6261e-04, -1.4831e-02,  4.3763e-01,  1.8991e-01,
         -1.0874e-01],
        [-3.2428e-03, -3.1999e-05, -1.5140e-02,  4.3537e-01,  1.9555e-01,
         -1.0836e-01]], device='cuda:0')
2025-04-25 16:41:56,801 - INFO - Epoch 11/100, Train Loss: 0.016042, Valid Loss: 0.145829, ETA: 2:52:28
2025-04-25 16:41:57,752 - INFO - New best training loss: 0.016042
2025-04-25 16:42:10,444 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:42:10,447 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:42:10,447 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:42:10,450 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:42:10,454 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-9.0015e-06,  2.2688e-03,  3.2931e-05,  7.7961e-01,  1.6376e-01,
         -7.9537e-02],
        [-1.9231e-05,  2.2110e-03,  2.3492e-05,  7.7982e-01,  1.6353e-01,
         -7.8847e-02],
        [-3.0378e-05,  2.1188e-03,  1.2361e-05,  7.7998e-01,  1.6331e-01,
         -7.8227e-02]], device='cuda:0')
2025-04-25 16:43:19,113 - INFO - Training trajectories: [('Kite_training/sunny', 'trajectory_0000'), ('Kite_training/sunny', 'trajectory_0001'), ('Kite_training/sunny', 'trajectory_0002'), ('Kite_training/sunny', 'trajectory_0003'), ('Kite_training/sunny', 'trajectory_0004'), ('Kite_training/sunny', 'trajectory_0005'), ('Kite_training/sunny', 'trajectory_0006'), ('Kite_training/sunny', 'trajectory_0007')], Count: 8
2025-04-25 16:43:19,114 - INFO - Validation trajectories: [('Kite_training/sunny', 'trajectory_0008'), ('Kite_training/sunny', 'trajectory_0009'), ('Kite_training/sunny', 'trajectory_0010'), ('Kite_training/sunny', 'trajectory_0011'), ('Kite_training/sunny', 'trajectory_0012'), ('Kite_training/sunny', 'trajectory_0013'), ('Kite_training/sunny', 'trajectory_0014')], Count: 7
2025-04-25 16:43:19,197 - INFO - Using existing data info files with 15 trajectories
2025-04-25 16:43:19,197 - INFO - Number of training samples: 5871
2025-04-25 16:43:19,198 - INFO - Number of validation samples: 1713
2025-04-25 16:43:19,305 - INFO - Number of training batches: 244
2025-04-25 16:43:19,305 - INFO - Number of validation batches: 71
2025-04-25 16:43:19,305 - INFO - Instantiating RGBVO model
2025-04-25 16:43:19,884 - INFO - 
==== MODEL DIAGNOSIS ====
2025-04-25 16:43:19,884 - INFO - Model type: rgb
2025-04-25 16:43:19,884 - INFO - Model class: RGBVO
2025-04-25 16:43:19,885 - INFO - Total parameters: 80,687,878
2025-04-25 16:43:19,885 - INFO - Trainable parameters: 80,687,878
2025-04-25 16:43:19,889 - DEBUG - rgb_deepvo.conv1.0.weight: shape=torch.Size([64, 6, 7, 7]), mean=0.0003, std=0.0829
2025-04-25 16:43:19,895 - DEBUG - rgb_deepvo.conv1.1.weight: shape=torch.Size([64]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,895 - DEBUG - rgb_deepvo.conv1.1.bias: shape=torch.Size([64]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,895 - DEBUG - rgb_deepvo.conv2.0.weight: shape=torch.Size([128, 64, 5, 5]), mean=0.0000, std=0.0353
2025-04-25 16:43:19,895 - DEBUG - rgb_deepvo.conv2.1.weight: shape=torch.Size([128]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,895 - DEBUG - rgb_deepvo.conv2.1.bias: shape=torch.Size([128]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv3.0.weight: shape=torch.Size([256, 128, 5, 5]), mean=0.0000, std=0.0250
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv3.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv3.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv3_1.0.weight: shape=torch.Size([256, 256, 3, 3]), mean=-0.0000, std=0.0295
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv3_1.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv3_1.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv4.0.weight: shape=torch.Size([512, 256, 3, 3]), mean=-0.0000, std=0.0294
2025-04-25 16:43:19,896 - DEBUG - rgb_deepvo.conv4.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv4.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv4_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv4_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv4_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv5.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv5.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv5.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,897 - DEBUG - rgb_deepvo.conv5_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=0.0000, std=0.0208
2025-04-25 16:43:19,898 - DEBUG - rgb_deepvo.conv5_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,898 - DEBUG - rgb_deepvo.conv5_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,898 - DEBUG - rgb_deepvo.conv6.0.weight: shape=torch.Size([1024, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 16:43:19,898 - DEBUG - rgb_deepvo.conv6.1.weight: shape=torch.Size([1024]), mean=1.0000, std=0.0000
2025-04-25 16:43:19,898 - DEBUG - rgb_deepvo.conv6.1.bias: shape=torch.Size([1024]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,899 - DEBUG - rgb_deepvo.rnn.weight_ih_l0: shape=torch.Size([2048, 30720]), mean=0.0000, std=0.0081
2025-04-25 16:43:19,901 - DEBUG - rgb_deepvo.rnn.weight_hh_l0: shape=torch.Size([2048, 512]), mean=-0.0001, std=0.0625
2025-04-25 16:43:19,901 - DEBUG - rgb_deepvo.rnn.bias_ih_l0: shape=torch.Size([2048]), mean=0.2500, std=0.4331
2025-04-25 16:43:19,901 - DEBUG - rgb_deepvo.rnn.bias_hh_l0: shape=torch.Size([2048]), mean=0.2500, std=0.4331
2025-04-25 16:43:19,902 - DEBUG - rgb_deepvo.rnn.weight_ih_l1: shape=torch.Size([2048, 512]), mean=0.0001, std=0.0625
2025-04-25 16:43:19,902 - DEBUG - rgb_deepvo.rnn.weight_hh_l1: shape=torch.Size([2048, 512]), mean=-0.0000, std=0.0625
2025-04-25 16:43:19,902 - DEBUG - rgb_deepvo.rnn.bias_ih_l1: shape=torch.Size([2048]), mean=0.2500, std=0.4331
2025-04-25 16:43:19,902 - DEBUG - rgb_deepvo.rnn.bias_hh_l1: shape=torch.Size([2048]), mean=0.2500, std=0.4331
2025-04-25 16:43:19,903 - DEBUG - rgb_deepvo.linear.weight: shape=torch.Size([6, 512]), mean=0.0014, std=0.0636
2025-04-25 16:43:19,903 - DEBUG - rgb_deepvo.linear.bias: shape=torch.Size([6]), mean=0.0000, std=0.0000
2025-04-25 16:43:19,903 - INFO - Testing forward pass with dummy data...
2025-04-25 16:43:19,908 - INFO - Forward pass successful. Output shape: torch.Size([2, 9, 6])
2025-04-25 16:43:19,909 - INFO - Model has 64 parameters
2025-04-25 16:43:19,909 - INFO - Sample model keys: ['rgb_deepvo.conv1.0.weight', 'rgb_deepvo.conv1.1.weight', 'rgb_deepvo.conv1.1.bias', 'rgb_deepvo.conv1.1.running_mean', 'rgb_deepvo.conv1.1.running_var', 'rgb_deepvo.conv1.1.num_batches_tracked', 'rgb_deepvo.conv2.0.weight', 'rgb_deepvo.conv2.1.weight', 'rgb_deepvo.conv2.1.bias', 'rgb_deepvo.conv2.1.running_mean']
2025-04-25 16:43:19,909 - INFO - Target prefixes that exist in model: ['rgb_deepvo']
2025-04-25 16:43:19,909 - INFO - Extended target prefixes: ['rgb_deepvo', 'rgb_deepvo.conv1', 'rgb_deepvo.conv2', 'rgb_deepvo.conv3', 'rgb_deepvo.conv3_1', 'rgb_deepvo.conv4', 'rgb_deepvo.conv4_1', 'rgb_deepvo.conv5', 'rgb_deepvo.conv5_1', 'rgb_deepvo.conv6']
2025-04-25 16:43:19,909 - INFO - Loading pre-trained FlowNet weights from /home/krkavinda/DeepVO-pytorch/FlowNet_models/pytorch/flownets_bn_EPE2.459.pth
2025-04-25 16:43:19,987 - INFO - Found 'state_dict' key in weights file, using it for loading
2025-04-25 16:43:19,987 - INFO - Found 45 matches using prefixes
2025-04-25 16:43:19,988 - INFO - Successfully loaded 45 layers from FlowNet weights
2025-04-25 16:43:19,988 - INFO -   - 45 layers matched for rgb_deepvo
2025-04-25 16:43:19,988 - INFO - 
==== VALIDATING DATALOADERS ====
2025-04-25 16:43:19,988 - INFO - Checking Training dataloader...
2025-04-25 16:43:36,505 - INFO - Training batch sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:43:36,505 - INFO - Training RGB shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:43:36,526 - INFO - Training RGB stats: min=-4.2093, max=0.5773, mean=-2.0859
2025-04-25 16:43:36,557 - INFO - Training Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:43:36,562 - INFO - Training Ground truth stats: min=-0.8689, max=0.7852, mean=0.0452
2025-04-25 16:43:36,562 - INFO - Training Trajectory IDs: [['Kite_training/sunny', 'trajectory_0003'], ['Kite_training/sunny', 'trajectory_0001'], ['Kite_training/sunny', 'trajectory_0006']]
2025-04-25 16:43:36,576 - INFO - Training forward pass successful. Output shape: torch.Size([24, 9, 6])
2025-04-25 16:43:36,576 - INFO - Training loss calculation successful. Loss: 0.093800
2025-04-25 16:43:36,576 - INFO - Checking Validation dataloader...
2025-04-25 16:43:50,475 - INFO - Validation batch sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:43:50,475 - INFO - Validation RGB shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:43:50,495 - INFO - Validation RGB stats: min=-4.2093, max=0.5773, mean=-1.8556
2025-04-25 16:43:50,525 - INFO - Validation Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:43:50,525 - INFO - Validation Ground truth stats: min=-0.8760, max=0.7663, mean=0.0187
2025-04-25 16:43:50,525 - INFO - Validation Trajectory IDs: [['Kite_training/sunny', 'trajectory_0011'], ['Kite_training/sunny', 'trajectory_0010'], ['Kite_training/sunny', 'trajectory_0012']]
2025-04-25 16:43:50,528 - INFO - Validation forward pass successful. Output shape: torch.Size([24, 9, 6])
2025-04-25 16:43:50,529 - INFO - Validation loss calculation successful. Loss: 0.107969
2025-04-25 16:43:50,529 - INFO - 
==== VALIDATING LOSS CALCULATION ====
2025-04-25 16:43:59,950 - INFO - Batch 0: Model loss = 0.089516, Manual loss = 0.089516
2025-04-25 16:43:59,951 - INFO -   Difference: 0.000000
2025-04-25 16:43:59,998 - INFO - Batch 1: Model loss = 0.088861, Manual loss = 0.088861
2025-04-25 16:43:59,998 - INFO -   Difference: 0.000000
2025-04-25 16:44:02,204 - INFO - Batch 2: Model loss = 0.092392, Manual loss = 0.092392
2025-04-25 16:44:02,205 - INFO -   Difference: 0.000000
2025-04-25 16:44:02,257 - INFO - Batch 3: Model loss = 0.080383, Manual loss = 0.080383
2025-04-25 16:44:02,258 - INFO -   Difference: 0.000000
2025-04-25 16:44:02,311 - INFO - Batch 4: Model loss = 0.101147, Manual loss = 0.101147
2025-04-25 16:44:02,312 - INFO -   Difference: 0.000000
2025-04-25 16:44:04,109 - INFO - Validated 5 batches.
2025-04-25 16:44:04,109 - INFO - Average validation loss: 0.090460
2025-04-25 16:44:04,109 - INFO - Min: 0.080383, Max: 0.101147
2025-04-25 16:44:04,109 - INFO - Starting training for 100 epochs
2025-04-25 16:44:13,964 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 16:44:13,967 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:44:13,967 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:44:13,971 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:44:14,027 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0026,  0.0011,  0.0115,  0.0613,  0.4132, -0.0117],
        [-0.0027,  0.0009,  0.0115,  0.0622,  0.4130, -0.0103],
        [-0.0027,  0.0008,  0.0115,  0.0630,  0.4128, -0.0089]],
       device='cuda:0')
2025-04-25 16:45:23,117 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 16:45:23,120 - INFO - Sequence lengths: [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
2025-04-25 16:45:23,121 - INFO - rgb tensor shape: torch.Size([24, 10, 3, 184, 608])
2025-04-25 16:45:23,124 - INFO - Ground truth shape: torch.Size([24, 9, 6])
2025-04-25 16:45:23,128 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0009, -0.0032,  0.0116, -0.1353, -0.3707, -0.0111],
        [ 0.0011, -0.0030,  0.0117, -0.1354, -0.3691, -0.0147],
        [ 0.0014, -0.0028,  0.0118, -0.1356, -0.3676, -0.0184]],
       device='cuda:0')
