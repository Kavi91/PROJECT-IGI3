2025-04-24 12:26:46,403 - INFO - Training trajectories: [('Kite_training/sunny', 'trajectory_0000'), ('Kite_training/sunny', 'trajectory_0001'), ('Kite_training/sunny', 'trajectory_0002'), ('Kite_training/sunny', 'trajectory_0003'), ('Kite_training/sunny', 'trajectory_0004'), ('Kite_training/sunny', 'trajectory_0005')], Count: 6
2025-04-24 12:26:46,403 - INFO - Validation trajectories: [('Kite_training/sunny', 'trajectory_0006'), ('Kite_training/sunny', 'trajectory_0007'), ('Kite_training/sunny', 'trajectory_0008'), ('Kite_training/sunny', 'trajectory_0009')], Count: 4
2025-04-24 12:26:46,403 - INFO - Generating new data info (files not found)
2025-04-24 12:26:46,634 - INFO - Number of training samples: 7958
2025-04-24 12:26:46,634 - INFO - Number of validation samples: 2204
2025-04-24 12:26:46,775 - INFO - Number of training batches: 330
2025-04-24 12:26:46,775 - INFO - Number of validation batches: 91
2025-04-24 12:26:46,775 - INFO - Instantiating RGBVO model
2025-04-24 12:26:47,689 - INFO - Loading pre-trained FlowNet weights from /home/krkavinda/DeepVO-pytorch/FlowNet_models/pytorch/flownets_bn_EPE2.459.pth
2025-04-24 12:26:47,745 - WARNING - No matching layers found between FlowNet weights and model architecture
2025-04-24 12:26:47,746 - INFO - Starting training for 100 epochs
2025-04-24 12:29:50,598 - INFO - Epoch 1/100, Train Loss: 1.194215, Valid Loss: 0.110198, ETA: 5:01:42
2025-04-24 12:29:51,965 - INFO - New best validation loss: 0.110198
2025-04-24 12:29:53,281 - INFO - New best training loss: 1.194215
2025-04-24 12:33:00,648 - INFO - Epoch 2/100, Train Loss: 0.129737, Valid Loss: 0.080344, ETA: 5:02:20
2025-04-24 12:33:02,467 - INFO - New best validation loss: 0.080344
2025-04-24 12:33:04,180 - INFO - New best training loss: 0.129737
2025-04-24 12:36:12,830 - INFO - Epoch 3/100, Train Loss: 0.090029, Valid Loss: 0.080093, ETA: 5:01:10
2025-04-24 12:36:14,617 - INFO - New best validation loss: 0.080093
2025-04-24 12:36:16,358 - INFO - New best training loss: 0.090029
2025-04-24 12:39:21,530 - INFO - Epoch 4/100, Train Loss: 0.085846, Valid Loss: 0.087204, ETA: 4:57:36
2025-04-24 12:39:23,315 - INFO - New best training loss: 0.085846
2025-04-24 12:42:24,557 - INFO - Epoch 5/100, Train Loss: 0.084832, Valid Loss: 0.090880, ETA: 4:53:00
2025-04-24 12:42:26,360 - INFO - New best training loss: 0.084832
2025-04-24 12:42:27,653 - INFO - Saved checkpoint at epoch 5
2025-04-25 02:46:44,626 - INFO - Training trajectories: [('Kite_training/sunny', 'trajectory_0000'), ('Kite_training/sunny', 'trajectory_0001'), ('Kite_training/sunny', 'trajectory_0002'), ('Kite_training/sunny', 'trajectory_0003'), ('Kite_training/sunny', 'trajectory_0004'), ('Kite_training/sunny', 'trajectory_0005')], Count: 6
2025-04-25 02:46:44,627 - INFO - Validation trajectories: [('Kite_training/sunny', 'trajectory_0006'), ('Kite_training/sunny', 'trajectory_0007'), ('Kite_training/sunny', 'trajectory_0008'), ('Kite_training/sunny', 'trajectory_0009')], Count: 4
2025-04-25 02:46:44,707 - INFO - Using existing data info files with 10 trajectories
2025-04-25 02:46:44,707 - INFO - Number of training samples: 7958
2025-04-25 02:46:44,707 - INFO - Number of validation samples: 1763
2025-04-25 02:46:44,842 - INFO - Number of training batches: 330
2025-04-25 02:46:44,843 - INFO - Number of validation batches: 73
2025-04-25 02:46:44,843 - INFO - Instantiating RGBVO model
2025-04-25 02:46:45,826 - INFO - Model has 64 parameters
2025-04-25 02:46:45,826 - INFO - Sample model keys: ['rgb_deepvo.conv1.0.weight', 'rgb_deepvo.conv1.1.weight', 'rgb_deepvo.conv1.1.bias', 'rgb_deepvo.conv1.1.running_mean', 'rgb_deepvo.conv1.1.running_var', 'rgb_deepvo.conv1.1.num_batches_tracked', 'rgb_deepvo.conv2.0.weight', 'rgb_deepvo.conv2.1.weight', 'rgb_deepvo.conv2.1.bias', 'rgb_deepvo.conv2.1.running_mean']
2025-04-25 02:46:45,826 - INFO - Target prefixes that exist in model: []
2025-04-25 02:46:45,826 - INFO - Extended target prefixes: ['rgb_deepvo.flownet', 'rgb_deepvo.conv1', 'rgb_deepvo.conv2', 'rgb_deepvo.conv3', 'rgb_deepvo.conv3_1', 'rgb_deepvo.conv4', 'rgb_deepvo.conv4_1', 'rgb_deepvo.conv5', 'rgb_deepvo.conv5_1', 'rgb_deepvo.conv6', 'rgb_deepvo_flownet']
2025-04-25 02:46:45,826 - INFO - Loading pre-trained FlowNet weights from /home/krkavinda/DeepVO-pytorch/FlowNet_models/pytorch/flownets_bn_EPE2.459.pth
2025-04-25 02:46:45,905 - INFO - FlowNet weights file contains 4 keys: ['state_dict', 'epoch', 'arch', 'best_EPE']
2025-04-25 02:46:45,905 - INFO - Found 'state_dict' key in weights file, using it for loading
2025-04-25 02:46:45,905 - INFO - Pretrained weights contain 63 parameters
2025-04-25 02:46:45,905 - INFO - Sample weight keys: ['conv1.0.weight', 'conv1.1.weight', 'conv1.1.bias', 'conv1.1.running_mean', 'conv1.1.running_var']
2025-04-25 02:46:45,906 - INFO - No key matches found, attempting shape-based matching...
2025-04-25 02:46:45,906 - INFO - Matched 45 layers by shape
2025-04-25 02:46:45,907 - INFO - Successfully loaded 45 layers from FlowNet weights
2025-04-25 02:46:45,907 - INFO - Starting training for 100 epochs
2025-04-25 02:49:49,528 - INFO - Epoch 1/100, Train Loss: 0.708304, Valid Loss: 0.813228, ETA: 5:02:58
2025-04-25 02:49:51,408 - INFO - New best validation loss: 0.813228
2025-04-25 02:49:53,217 - INFO - New best training loss: 0.708304
2025-04-25 02:53:00,260 - INFO - Epoch 2/100, Train Loss: 0.283249, Valid Loss: 0.204331, ETA: 5:02:42
2025-04-25 02:53:02,110 - INFO - New best validation loss: 0.204331
2025-04-25 02:53:04,009 - INFO - New best training loss: 0.283249
2025-04-25 02:56:10,083 - INFO - Epoch 3/100, Train Loss: 0.155512, Valid Loss: 0.081585, ETA: 5:00:01
2025-04-25 02:56:11,969 - INFO - New best validation loss: 0.081585
2025-04-25 02:56:13,801 - INFO - New best training loss: 0.155512
2025-04-25 02:59:21,897 - INFO - Epoch 4/100, Train Loss: 0.110248, Valid Loss: 0.069458, ETA: 4:57:55
2025-04-25 02:59:23,760 - INFO - New best validation loss: 0.069458
2025-04-25 02:59:25,602 - INFO - New best training loss: 0.110248
2025-04-25 03:02:26,013 - INFO - Epoch 5/100, Train Loss: 0.095109, Valid Loss: 0.067782, ETA: 4:52:59
2025-04-25 03:02:27,863 - INFO - New best validation loss: 0.067782
2025-04-25 03:02:29,707 - INFO - New best training loss: 0.095109
2025-04-25 03:02:31,655 - INFO - Saved checkpoint at epoch 5
2025-04-25 03:05:38,059 - INFO - Epoch 6/100, Train Loss: 0.083891, Valid Loss: 0.066260, ETA: 4:50:43
2025-04-25 03:05:39,934 - INFO - New best validation loss: 0.066260
2025-04-25 03:05:41,818 - INFO - New best training loss: 0.083891
2025-04-25 03:08:44,810 - INFO - Epoch 7/100, Train Loss: 0.076971, Valid Loss: 0.068798, ETA: 4:46:21
2025-04-25 03:08:46,653 - INFO - New best training loss: 0.076971
2025-04-25 14:49:50,975 - INFO - Training trajectories: [('Kite_training/sunny', 'trajectory_0000'), ('Kite_training/sunny', 'trajectory_0001'), ('Kite_training/sunny', 'trajectory_0002'), ('Kite_training/sunny', 'trajectory_0003'), ('Kite_training/sunny', 'trajectory_0004'), ('Kite_training/sunny', 'trajectory_0005'), ('Kite_training/sunny', 'trajectory_0006'), ('Kite_training/sunny', 'trajectory_0007')], Count: 8
2025-04-25 14:49:50,976 - INFO - Validation trajectories: [('Kite_training/sunny', 'trajectory_0008'), ('Kite_training/sunny', 'trajectory_0009'), ('Kite_training/sunny', 'trajectory_0010'), ('Kite_training/sunny', 'trajectory_0011'), ('Kite_training/sunny', 'trajectory_0012'), ('Kite_training/sunny', 'trajectory_0013'), ('Kite_training/sunny', 'trajectory_0014')], Count: 7
2025-04-25 14:49:50,976 - INFO - Generating new data info (files not found)
2025-04-25 14:49:51,309 - INFO - Number of training samples: 13236
2025-04-25 14:49:51,309 - INFO - Number of validation samples: 3860
2025-04-25 14:49:51,542 - INFO - Number of training batches: 551
2025-04-25 14:49:51,542 - INFO - Number of validation batches: 160
2025-04-25 14:49:51,542 - INFO - Instantiating RGBVO model
2025-04-25 14:49:52,510 - INFO - 
==== MODEL DIAGNOSIS ====
2025-04-25 14:49:52,510 - INFO - Model type: rgb
2025-04-25 14:49:52,510 - INFO - Model class: RGBVO
2025-04-25 14:49:52,510 - INFO - Total parameters: 149,518,326
2025-04-25 14:49:52,510 - INFO - Trainable parameters: 149,518,326
2025-04-25 14:49:52,514 - DEBUG - rgb_deepvo.conv1.0.weight: shape=torch.Size([64, 6, 7, 7]), mean=-0.0001, std=0.0820
2025-04-25 14:49:52,520 - DEBUG - rgb_deepvo.conv1.1.weight: shape=torch.Size([64]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,520 - DEBUG - rgb_deepvo.conv1.1.bias: shape=torch.Size([64]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,520 - DEBUG - rgb_deepvo.conv2.0.weight: shape=torch.Size([128, 64, 5, 5]), mean=0.0000, std=0.0353
2025-04-25 14:49:52,520 - DEBUG - rgb_deepvo.conv2.1.weight: shape=torch.Size([128]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,520 - DEBUG - rgb_deepvo.conv2.1.bias: shape=torch.Size([128]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv3.0.weight: shape=torch.Size([256, 128, 5, 5]), mean=0.0000, std=0.0250
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv3.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv3.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv3_1.0.weight: shape=torch.Size([256, 256, 3, 3]), mean=-0.0001, std=0.0294
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv3_1.1.weight: shape=torch.Size([256]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv3_1.1.bias: shape=torch.Size([256]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv4.0.weight: shape=torch.Size([512, 256, 3, 3]), mean=-0.0000, std=0.0294
2025-04-25 14:49:52,521 - DEBUG - rgb_deepvo.conv4.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv4.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv4_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=0.0000, std=0.0208
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv4_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv4_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv5.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv5.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv5.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,522 - DEBUG - rgb_deepvo.conv5_1.0.weight: shape=torch.Size([512, 512, 3, 3]), mean=0.0000, std=0.0208
2025-04-25 14:49:52,523 - DEBUG - rgb_deepvo.conv5_1.1.weight: shape=torch.Size([512]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,523 - DEBUG - rgb_deepvo.conv5_1.1.bias: shape=torch.Size([512]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,523 - DEBUG - rgb_deepvo.conv6.0.weight: shape=torch.Size([1024, 512, 3, 3]), mean=-0.0000, std=0.0208
2025-04-25 14:49:52,523 - DEBUG - rgb_deepvo.conv6.1.weight: shape=torch.Size([1024]), mean=1.0000, std=0.0000
2025-04-25 14:49:52,523 - DEBUG - rgb_deepvo.conv6.1.bias: shape=torch.Size([1024]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,525 - DEBUG - rgb_deepvo.rnn.weight_ih_l0: shape=torch.Size([4000, 30720]), mean=0.0000, std=0.0081
2025-04-25 14:49:52,528 - DEBUG - rgb_deepvo.rnn.weight_hh_l0: shape=torch.Size([4000, 1000]), mean=0.0000, std=0.0447
2025-04-25 14:49:52,528 - DEBUG - rgb_deepvo.rnn.bias_ih_l0: shape=torch.Size([4000]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,528 - DEBUG - rgb_deepvo.rnn.bias_hh_l0: shape=torch.Size([4000]), mean=0.2500, std=0.4331
2025-04-25 14:49:52,529 - DEBUG - rgb_deepvo.rnn.weight_ih_l1: shape=torch.Size([4000, 1000]), mean=0.0000, std=0.0447
2025-04-25 14:49:52,529 - DEBUG - rgb_deepvo.rnn.weight_hh_l1: shape=torch.Size([4000, 1000]), mean=-0.0000, std=0.0447
2025-04-25 14:49:52,529 - DEBUG - rgb_deepvo.rnn.bias_ih_l1: shape=torch.Size([4000]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,529 - DEBUG - rgb_deepvo.rnn.bias_hh_l1: shape=torch.Size([4000]), mean=0.2500, std=0.4331
2025-04-25 14:49:52,529 - DEBUG - rgb_deepvo.linear.weight: shape=torch.Size([6, 1000]), mean=-0.0004, std=0.0445
2025-04-25 14:49:52,529 - DEBUG - rgb_deepvo.linear.bias: shape=torch.Size([6]), mean=0.0000, std=0.0000
2025-04-25 14:49:52,529 - INFO - Testing forward pass with dummy data...
2025-04-25 14:49:52,615 - INFO - Forward pass successful. Output shape: torch.Size([2, 4, 6])
2025-04-25 14:49:52,615 - INFO - Model has 64 parameters
2025-04-25 14:49:52,615 - INFO - Sample model keys: ['rgb_deepvo.conv1.0.weight', 'rgb_deepvo.conv1.1.weight', 'rgb_deepvo.conv1.1.bias', 'rgb_deepvo.conv1.1.running_mean', 'rgb_deepvo.conv1.1.running_var', 'rgb_deepvo.conv1.1.num_batches_tracked', 'rgb_deepvo.conv2.0.weight', 'rgb_deepvo.conv2.1.weight', 'rgb_deepvo.conv2.1.bias', 'rgb_deepvo.conv2.1.running_mean']
2025-04-25 14:49:52,615 - INFO - Target prefixes that exist in model: ['rgb_deepvo']
2025-04-25 14:49:52,615 - INFO - Extended target prefixes: ['rgb_deepvo', 'rgb_deepvo.conv1', 'rgb_deepvo.conv2', 'rgb_deepvo.conv3', 'rgb_deepvo.conv3_1', 'rgb_deepvo.conv4', 'rgb_deepvo.conv4_1', 'rgb_deepvo.conv5', 'rgb_deepvo.conv5_1', 'rgb_deepvo.conv6']
2025-04-25 14:49:52,616 - INFO - Loading pre-trained FlowNet weights from /home/krkavinda/DeepVO-pytorch/FlowNet_models/pytorch/flownets_bn_EPE2.459.pth
2025-04-25 14:49:52,707 - INFO - Found 'state_dict' key in weights file, using it for loading
2025-04-25 14:49:52,707 - INFO - Found 45 matches using prefixes
2025-04-25 14:49:52,708 - INFO - Successfully loaded 45 layers from FlowNet weights
2025-04-25 14:49:52,708 - INFO -   - 45 layers matched for rgb_deepvo
2025-04-25 14:49:52,708 - INFO - 
==== VALIDATING DATALOADERS ====
2025-04-25 14:49:52,708 - INFO - Checking Training dataloader...
2025-04-25 14:50:00,633 - INFO - Training batch sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:50:00,633 - INFO - Training RGB shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:50:00,643 - INFO - Training RGB stats: min=-4.2093, max=0.5773, mean=-2.0010
2025-04-25 14:50:00,656 - INFO - Training Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:50:00,658 - INFO - Training Ground truth stats: min=-0.6676, max=0.8003, mean=0.0102
2025-04-25 14:50:00,659 - INFO - Training Trajectory IDs: [['Kite_training/sunny', 'trajectory_0000'], ['Kite_training/sunny', 'trajectory_0003'], ['Kite_training/sunny', 'trajectory_0007']]
2025-04-25 14:50:00,747 - INFO - Training forward pass successful. Output shape: torch.Size([24, 4, 6])
2025-04-25 14:50:00,747 - INFO - Training loss calculation successful. Loss: 2.763773
2025-04-25 14:50:00,747 - INFO - Checking Validation dataloader...
2025-04-25 14:50:07,253 - INFO - Validation batch sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:50:07,254 - INFO - Validation RGB shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:50:07,264 - INFO - Validation RGB stats: min=-4.2093, max=0.5773, mean=-2.0305
2025-04-25 14:50:07,278 - INFO - Validation Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:50:07,279 - INFO - Validation Ground truth stats: min=-0.5497, max=0.6360, mean=0.0297
2025-04-25 14:50:07,279 - INFO - Validation Trajectory IDs: [['Kite_training/sunny', 'trajectory_0010'], ['Kite_training/sunny', 'trajectory_0011'], ['Kite_training/sunny', 'trajectory_0013']]
2025-04-25 14:50:07,362 - INFO - Validation forward pass successful. Output shape: torch.Size([24, 4, 6])
2025-04-25 14:50:07,362 - INFO - Validation loss calculation successful. Loss: 2.331728
2025-04-25 14:50:07,363 - INFO - 
==== VALIDATING LOSS CALCULATION ====
2025-04-25 14:50:13,704 - INFO - Batch 0: Model loss = 3.697716, Manual loss = 3.697716
2025-04-25 14:50:13,707 - INFO -   Difference: 0.000000
2025-04-25 14:50:13,817 - INFO - Batch 1: Model loss = 3.503611, Manual loss = 3.503610
2025-04-25 14:50:13,818 - INFO -   Difference: 0.000000
2025-04-25 14:50:13,928 - INFO - Batch 2: Model loss = 4.038872, Manual loss = 4.038872
2025-04-25 14:50:13,929 - INFO -   Difference: 0.000000
2025-04-25 14:50:14,038 - INFO - Batch 3: Model loss = 2.964892, Manual loss = 2.964892
2025-04-25 14:50:14,039 - INFO -   Difference: 0.000000
2025-04-25 14:50:14,143 - INFO - Batch 4: Model loss = 2.809994, Manual loss = 2.809994
2025-04-25 14:50:14,144 - INFO -   Difference: 0.000000
2025-04-25 14:50:15,369 - INFO - Validated 5 batches.
2025-04-25 14:50:15,369 - INFO - Average validation loss: 3.403017
2025-04-25 14:50:15,369 - INFO - Min: 2.809994, Max: 4.038872
2025-04-25 14:50:15,369 - INFO - Starting training for 100 epochs
2025-04-25 14:50:19,788 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 14:50:19,790 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:50:19,791 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:50:19,792 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:50:19,844 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-5.2254e-03,  3.3807e-04, -1.0223e-02,  7.5757e-01,  1.4010e-01,
         -8.3659e-02],
        [-5.4906e-03,  4.0926e-04, -9.6617e-03,  7.5608e-01,  1.4748e-01,
         -8.2785e-02],
        [-5.7055e-03,  4.9009e-04, -9.0921e-03,  7.5465e-01,  1.5434e-01,
         -8.1810e-02]], device='cuda:0')
2025-04-25 14:51:58,984 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 14:51:58,988 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:51:58,988 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:51:58,990 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:51:58,994 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0015, -0.0020,  0.0073, -0.3410,  0.5315,  0.0659],
        [ 0.0014, -0.0014,  0.0073, -0.3368,  0.5346,  0.0674],
        [ 0.0014, -0.0007,  0.0073, -0.3325,  0.5377,  0.0688]],
       device='cuda:0')
2025-04-25 14:52:25,418 - INFO - Epoch 1/100, Train Loss: 0.789399, Valid Loss: 0.115705, ETA: 3:34:34
2025-04-25 14:52:26,839 - INFO - New best validation loss: 0.115705
2025-04-25 14:52:28,197 - INFO - New best training loss: 0.789399
2025-04-25 14:52:33,860 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 14:52:33,862 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:52:33,862 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:52:33,863 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:52:33,865 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 1.9140e-04, -4.0464e-04,  1.6389e-04,  9.4489e-02,  7.9982e-01,
          1.2056e-02],
        [ 1.9569e-04, -4.8228e-04,  1.2947e-04,  9.3483e-02,  7.9987e-01,
          1.1874e-02],
        [ 1.8609e-04, -5.4406e-04,  1.0790e-04,  9.2456e-02,  7.9994e-01,
          1.1706e-02]], device='cuda:0')
2025-04-25 14:54:09,778 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 14:54:09,783 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:54:09,784 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:54:09,786 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:54:09,791 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0022,  0.0039, -0.0230,  0.4246,  0.0935,  0.0158],
        [-0.0018,  0.0040, -0.0233,  0.4221,  0.1007,  0.0191],
        [-0.0015,  0.0040, -0.0233,  0.4195,  0.1082,  0.0225]],
       device='cuda:0')
2025-04-25 14:54:30,247 - INFO - Epoch 2/100, Train Loss: 0.148886, Valid Loss: 0.086401, ETA: 3:25:52
2025-04-25 14:54:32,050 - INFO - New best validation loss: 0.086401
2025-04-25 14:54:33,812 - INFO - New best training loss: 0.148886
2025-04-25 14:54:38,230 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 14:54:38,233 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:54:38,234 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:54:38,235 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:54:38,240 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0050, -0.0030,  0.0013, -0.5329, -0.2117,  0.0810],
        [-0.0051, -0.0029,  0.0013, -0.5353, -0.2101,  0.0810],
        [-0.0050, -0.0028,  0.0013, -0.5377, -0.2086,  0.0809]],
       device='cuda:0')
2025-04-25 14:56:15,978 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 14:56:15,981 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:56:15,982 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:56:15,984 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:56:15,988 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0025,  0.0013, -0.0122,  0.3670,  0.3009,  0.0586],
        [-0.0023,  0.0011, -0.0107,  0.3643,  0.3043,  0.0622],
        [-0.0021,  0.0009, -0.0093,  0.3620,  0.3070,  0.0659]],
       device='cuda:0')
2025-04-25 14:56:36,432 - INFO - Epoch 3/100, Train Loss: 0.076631, Valid Loss: 0.084899, ETA: 3:21:55
2025-04-25 14:56:38,182 - INFO - New best validation loss: 0.084899
2025-04-25 14:56:39,977 - INFO - New best training loss: 0.076631
2025-04-25 14:56:46,604 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 14:56:46,607 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:56:46,607 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:56:46,608 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:56:46,612 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0012, -0.0053,  0.0168, -0.4466, -0.1898,  0.0052],
        [ 0.0014, -0.0053,  0.0166, -0.4474, -0.1865,  0.0080],
        [ 0.0017, -0.0052,  0.0165, -0.4481, -0.1832,  0.0107]],
       device='cuda:0')
2025-04-25 14:58:22,507 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 14:58:22,511 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:58:22,511 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:58:22,514 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:58:22,518 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0033,  0.0022, -0.0101,  0.2945, -0.1266,  0.1402],
        [-0.0036,  0.0025, -0.0109,  0.2953, -0.1247,  0.1478],
        [-0.0038,  0.0028, -0.0115,  0.2962, -0.1228,  0.1552]],
       device='cuda:0')
2025-04-25 14:58:40,946 - INFO - Epoch 4/100, Train Loss: 0.058463, Valid Loss: 0.132688, ETA: 3:18:16
2025-04-25 14:58:42,743 - INFO - New best training loss: 0.058463
2025-04-25 14:58:49,406 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 14:58:49,409 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 14:58:49,409 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 14:58:49,411 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 14:58:49,415 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0028, -0.0027, -0.0130, -0.1941, -0.4120, -0.0551],
        [ 0.0027, -0.0027, -0.0133, -0.1928, -0.4132, -0.0557],
        [ 0.0025, -0.0027, -0.0133, -0.1912, -0.4144, -0.0565]],
       device='cuda:0')
2025-04-25 15:00:52,070 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 15:00:52,072 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 15:00:52,073 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 15:00:52,074 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 15:00:52,077 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0050,  0.0038, -0.0005,  0.1879,  0.2842,  0.0688],
        [-0.0054,  0.0040, -0.0005,  0.1883,  0.2850,  0.0728],
        [-0.0056,  0.0042, -0.0004,  0.1885,  0.2856,  0.0768]],
       device='cuda:0')
2025-04-25 15:01:12,246 - INFO - Epoch 5/100, Train Loss: 0.044424, Valid Loss: 0.128197, ETA: 3:24:18
2025-04-25 15:01:14,047 - INFO - New best training loss: 0.044424
2025-04-25 15:01:15,439 - INFO - Saved checkpoint at epoch 5
2025-04-25 15:01:21,858 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 15:01:21,863 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 15:01:21,864 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 15:01:21,865 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 15:01:21,867 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-1.1975e-03, -1.0075e-03, -1.8107e-04,  6.2452e-01,  7.4158e-02,
         -1.0363e-02],
        [-1.0007e-03, -9.0836e-04, -1.5853e-04,  6.2396e-01,  7.4380e-02,
         -1.0334e-02],
        [-8.2599e-04, -7.8164e-04, -1.3581e-04,  6.2342e-01,  7.4546e-02,
         -1.0272e-02]], device='cuda:0')
2025-04-25 15:02:58,194 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 15:02:58,198 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 15:02:58,198 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 15:02:58,200 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 15:02:58,204 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 2.2678e-03,  5.6132e-04, -2.8797e-03,  2.1953e-01, -2.0796e-01,
          1.8707e-01],
        [ 2.5827e-03,  5.5697e-05, -2.9428e-03,  2.1646e-01, -2.0944e-01,
          1.8463e-01],
        [ 2.9278e-03, -5.0896e-04, -2.9772e-03,  2.1352e-01, -2.1084e-01,
          1.8209e-01]], device='cuda:0')
2025-04-25 15:03:25,101 - INFO - Epoch 6/100, Train Loss: 0.035472, Valid Loss: 0.118252, ETA: 3:21:50
2025-04-25 15:03:26,800 - INFO - New best training loss: 0.035472
2025-04-25 15:03:30,658 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 15:03:30,661 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 15:03:30,662 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 15:03:30,663 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 15:03:30,667 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-6.8610e-04,  8.3103e-04,  3.8984e-04,  3.9039e-01, -2.9654e-02,
          6.7707e-02],
        [-8.1677e-04,  1.0204e-03,  3.9108e-04,  3.9043e-01, -2.9955e-02,
          7.5393e-02],
        [-9.4805e-04,  1.2234e-03,  3.5972e-04,  3.9043e-01, -3.0303e-02,
          8.3113e-02]], device='cuda:0')
2025-04-25 15:05:21,803 - INFO - 
VALIDATION BATCH DETAILS:
2025-04-25 15:05:21,806 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 15:05:21,807 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 15:05:21,809 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 15:05:21,813 - INFO - Ground truth sample (first item, first 3 frames): tensor([[-0.0013,  0.0004,  0.0023,  0.2140, -0.1998, -0.0190],
        [-0.0017,  0.0005,  0.0023,  0.2158, -0.1967, -0.0217],
        [-0.0022,  0.0007,  0.0022,  0.2175, -0.1937, -0.0246]],
       device='cuda:0')
2025-04-25 15:05:40,504 - INFO - Epoch 7/100, Train Loss: 0.029435, Valid Loss: 0.108725, ETA: 3:23:18
2025-04-25 15:05:42,175 - INFO - New best training loss: 0.029435
2025-04-25 15:05:45,968 - INFO - 
TRAINING BATCH DETAILS:
2025-04-25 15:05:45,972 - INFO - Sequence lengths: [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]
2025-04-25 15:05:45,972 - INFO - rgb tensor shape: torch.Size([24, 5, 3, 184, 608])
2025-04-25 15:05:45,974 - INFO - Ground truth shape: torch.Size([24, 4, 6])
2025-04-25 15:05:45,978 - INFO - Ground truth sample (first item, first 3 frames): tensor([[ 0.0030, -0.0013,  0.0076,  0.7408, -0.1653, -0.0173],
        [ 0.0031, -0.0012,  0.0077,  0.7402, -0.1716, -0.0166],
        [ 0.0032, -0.0011,  0.0078,  0.7396, -0.1780, -0.0159]],
       device='cuda:0')
